{"pageProps":{"mdMeta":{"realpath":"/home/runner/work/jokester.github.io/jokester.github.io/posts/2014/2014-05-11-memo-thinking-clearly-about-performance.markdown","slug":["2014-05-11","memo-thinking-clearly-about-performance"],"frontMatter":{"title":"memo: Thinking Clearly About Performance","publishAt":"2014-05-11"}},"mdContent":"\nThis post summaries an interesting paper called *Thinking Clearly About Performance*,\nby Cary Millsap.\n\n- Axiomatic approach\n\t- Trial-and-error approach of algebra:\n\t\t- When solving ``3x + 4 = 14``, try `x = 2`, `x = 3` and so on.\n\t\t- May work **sometimes**, yet still not a correct way for algebra.\n\t\t- Using it only indicates one is not thinking **clearly** about algebra.\n\t- Axiomatic approach of algebra (and other things):\n\t\t- Each step should be documented (and proven), reliable and repeatable.\n\t\t- One small, logical, provable and auditable step at a time.\n\t\t- Such steps form a proof of thinking clearly\n\t- Proving skill is vital\n\t\t- equally or more important than knowing\n\t\t- a must for good consultant / leader / employee\n\n- Definition of performance\n\t- `task`: a unit of work\n    - measurements:\n        - Response time: `#seconds per task`\n        - Throughput: `#tasks per second`\n        - Response and throughput must be measured separately\n            - they are not necessarily reciprocals\n            - one cannot derive response time only from throughput, vice versa.\n\t- Percentile specification:\n\t\t- e.g. \"95% of responses ended within 1s\"\n\t\t- maps better to the human experience than *mean* alone\n\t\t- captures both mean and variance\n\t- \"Our customers fell the variance, not the mean.\" --- GE, six sigma\n\n- Diagnosis of performance\n\t- The users' claim is often about the response time\n\t\t- simple form: \"It used to take only 1s\"\n\t\t- complex form: \"It's so [...] slow\"\n\t- First steps\n\t\t- State the problem clearly\n\t\t- Define the goal state\n\t\t\t- worse: when user does not understand a quantative goal\n\t\t\t- worse: when user's expectation is impossible to meet\n\t- Tool: sequence diagram\n\t- Tool: profile\n\t\t- pitfall: skew\n\t\t\t- non-uniformity in a list of values\n\t\t\t- eliminate 1/2 calls may not eliminate 1/2 execution time\n\t\t\t- skew histogram: group calls with (range of time / counts / total time)\n\t- Estimations:\n\t\t- cost\n\t\t- return\n\t\t\t- Amdahl's law: performance improvement is proportional to how much a program uses the improved thing\n\t\t- political capital: credibility in group\n\t\t- reliability of estimations\n\n\n- Efficiency\n\t- inverse measure of waste\n\t\t- waste: how much of service time can be eliminated\n\t\t\t- without adding capacity\n\t\t\t- without sacrificing function\n\t- do not adjust the program to accommodate inefficient programs\n\n- Load\n\t- Competition for resource induced by tasks\n\t- The reason that performance testing does not catch all problems in production\n\t- measurement: utilization (usage / capacity)\n\t- High load increases response time\n\n- Impacts of Load\n    - Queueing delay\n        - delay due to waiting\n        - can be modelled by \"M/M/m\" model\n            - ideal scalable queue\n        - total = service time + queueing delay\n        - high throughput and fast response are conflicting\n            - knee: optimal load\n            - min ( response time / utilization )\n            - the actual knee of an M/M/m system is listed in table (page 10 of the paper)\n            - when load is below knee: (marginal response time) is low.\n            - when load is beyond the knee: high (marginal response time), system become unusable quickly.\n    - Coherency delay\n        - delay due to shared resource\n        - cannot be modelled with \"M/M/m\" model\n\n- Testing\n\t- may not catch all problems, still necessary\n\t- keep balance between \"no test\" and \"complete emulation of production\"\n\n- Measuring for optimization\n\t - Throughtput: easier to measure\n\t - Response time: happens at client side, and is harder to measure\n\t - People tend to measure what's easy to measure\n\t - Surrogate measures:\n        - are easy to measure\n\t\t- may work **sometimes**\n        - know their limitation and use them wisely\n\t\t- e.g. subroutine call counts, samples (i.e. not all) of subroutine execution durations\n\n- Other principles\n    - Risk less in optimizing: when everybody is fine, do not adjust the world for one program\n    - Performance is a feature\n\t- Real performance is unrevealed until the production phase\n\t- Write the program so that it's easy to fix in production\n"},"__N_SSG":true}