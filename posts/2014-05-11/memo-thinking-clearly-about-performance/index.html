<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-39627402-1"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-39627402-1', {
              page_path: window.location.pathname,
            });
          </script><title>memo: Thinking Clearly About Performance</title><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="viewport" content="width=device-width, initial-scale=1,maximum-scale=1.5,minimum-scale=1"/><link rel="canonical" href="https://jokester.github.io/posts/2014-05-11/memo-thinking-clearly-about-performance"/><link rel="preload" href="/_next/static/css/cbf8b5770f5f30aa7698.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cbf8b5770f5f30aa7698.css" data-n-g=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-d42d109db6976c01a5e9.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.2a955b2cc4cd676398e3.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-7c12fd0ca2279e9deba3.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.e6a38dee2f8f3a7cf1e7.js" as="script"/><link rel="preload" href="/_next/static/chunks/b7536e739236ba09df46895b208080d021a349b5.79dc8a8b4f0d930fbecb.js" as="script"/><link rel="preload" href="/_next/static/chunks/b52a6c8fe9dfc388856b15614b0f9ba4172af7a6.1c0a2366dab843a4556e.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/posts/%5B...slug%5D-1862802d0a4a1972e3d1.js" as="script"/></head><body class="overflow-y-scroll"><div id="__next"><div class="bg-black text-yellow-100"><div class="min-h-screen container mx-auto"><div class="px-4 py-1 flex items-center bg-gray-900 space-x-4 text-sm"><a class="sm:hidden text-lg" href="/">挖坑自動機</a><a class="hidden sm:inline-block text-lg" href="/">挖坑自動機 / Digging automaton</a><span>|</span><a class="text-yellow-200" href="/posts/">/posts</a><a class="" href="/works/">/works</a><a class="" href="/about/">/about</a></div><div class="px-4 pt-6"><div class="markdown"><h1></h1><hr/><div class="markdown"><p>This post summaries an interesting paper called <em>Thinking Clearly About Performance</em>,
by Cary Millsap.</p><ul><li><p>Axiomatic approach</p><ul><li>Trial-and-error approach of algebra:<ul><li>When solving <code>3x + 4 = 14</code>, try <code>x = 2</code>, <code>x = 3</code> and so on.</li><li>May work <strong>sometimes</strong>, yet still not a correct way for algebra.</li><li>Using it only indicates one is not thinking <strong>clearly</strong> about algebra.</li></ul></li><li>Axiomatic approach of algebra (and other things):<ul><li>Each step should be documented (and proven), reliable and repeatable.</li><li>One small, logical, provable and auditable step at a time.</li><li>Such steps form a proof of thinking clearly</li></ul></li><li>Proving skill is vital<ul><li>equally or more important than knowing</li><li>a must for good consultant / leader / employee</li></ul></li></ul></li><li><p>Definition of performance</p><ul><li><code>task</code>: a unit of work</li><li>measurements:<ul><li>Response time: <code>#seconds per task</code></li><li>Throughput: <code>#tasks per second</code></li><li>Response and throughput must be measured separately<ul><li>they are not necessarily reciprocals</li><li>one cannot derive response time only from throughput, vice versa.</li></ul></li></ul></li><li>Percentile specification:<ul><li>e.g. &quot;95% of responses ended within 1s&quot;</li><li>maps better to the human experience than <em>mean</em> alone</li><li>captures both mean and variance</li></ul></li><li>&quot;Our customers fell the variance, not the mean.&quot; --- GE, six sigma</li></ul></li><li><p>Diagnosis of performance</p><ul><li>The users&#x27; claim is often about the response time<ul><li>simple form: &quot;It used to take only 1s&quot;</li><li>complex form: &quot;It&#x27;s so [...] slow&quot;</li></ul></li><li>First steps<ul><li>State the problem clearly</li><li>Define the goal state<ul><li>worse: when user does not understand a quantative goal</li><li>worse: when user&#x27;s expectation is impossible to meet</li></ul></li></ul></li><li>Tool: sequence diagram</li><li>Tool: profile<ul><li>pitfall: skew<ul><li>non-uniformity in a list of values</li><li>eliminate 1/2 calls may not eliminate 1/2 execution time</li><li>skew histogram: group calls with (range of time / counts / total time)</li></ul></li></ul></li><li>Estimations:<ul><li>cost</li><li>return<ul><li>Amdahl&#x27;s law: performance improvement is proportional to how much a program uses the improved thing</li></ul></li><li>political capital: credibility in group</li><li>reliability of estimations</li></ul></li></ul></li><li><p>Efficiency</p><ul><li>inverse measure of waste<ul><li>waste: how much of service time can be eliminated<ul><li>without adding capacity</li><li>without sacrificing function</li></ul></li></ul></li><li>do not adjust the program to accommodate inefficient programs</li></ul></li><li><p>Load</p><ul><li>Competition for resource induced by tasks</li><li>The reason that performance testing does not catch all problems in production</li><li>measurement: utilization (usage / capacity)</li><li>High load increases response time</li></ul></li><li><p>Impacts of Load</p><ul><li>Queueing delay<ul><li>delay due to waiting</li><li>can be modelled by &quot;M/M/m&quot; model<ul><li>ideal scalable queue</li></ul></li><li>total = service time + queueing delay</li><li>high throughput and fast response are conflicting<ul><li>knee: optimal load</li><li>min ( response time / utilization )</li><li>the actual knee of an M/M/m system is listed in table (page 10 of the paper)</li><li>when load is below knee: (marginal response time) is low.</li><li>when load is beyond the knee: high (marginal response time), system become unusable quickly.</li></ul></li></ul></li><li>Coherency delay<ul><li>delay due to shared resource</li><li>cannot be modelled with &quot;M/M/m&quot; model</li></ul></li></ul></li><li><p>Testing</p><ul><li>may not catch all problems, still necessary</li><li>keep balance between &quot;no test&quot; and &quot;complete emulation of production&quot;</li></ul></li><li><p>Measuring for optimization</p><ul><li>Throughtput: easier to measure</li><li>Response time: happens at client side, and is harder to measure</li><li>People tend to measure what&#x27;s easy to measure</li><li>Surrogate measures:<ul><li>are easy to measure</li><li>may work <strong>sometimes</strong></li><li>know their limitation and use them wisely</li><li>e.g. subroutine call counts, samples (i.e. not all) of subroutine execution durations</li></ul></li></ul></li><li><p>Other principles</p><ul><li>Risk less in optimizing: when everybody is fine, do not adjust the world for one program</li><li>Performance is a feature</li><li>Real performance is unrevealed until the production phase</li><li>Write the program so that it&#x27;s easy to fix in production</li></ul></li></ul></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"mdMeta":{"realpath":"/home/runner/work/jokester.github.io/jokester.github.io/posts/2014/2014-05-11-memo-thinking-clearly-about-performance.markdown","slug":["2014-05-11","memo-thinking-clearly-about-performance"],"frontMatter":{"title":"memo: Thinking Clearly About Performance","publishAt":"2014-05-11"}},"mdContent":"\nThis post summaries an interesting paper called *Thinking Clearly About Performance*,\nby Cary Millsap.\n\n- Axiomatic approach\n\t- Trial-and-error approach of algebra:\n\t\t- When solving ``3x + 4 = 14``, try `x = 2`, `x = 3` and so on.\n\t\t- May work **sometimes**, yet still not a correct way for algebra.\n\t\t- Using it only indicates one is not thinking **clearly** about algebra.\n\t- Axiomatic approach of algebra (and other things):\n\t\t- Each step should be documented (and proven), reliable and repeatable.\n\t\t- One small, logical, provable and auditable step at a time.\n\t\t- Such steps form a proof of thinking clearly\n\t- Proving skill is vital\n\t\t- equally or more important than knowing\n\t\t- a must for good consultant / leader / employee\n\n- Definition of performance\n\t- `task`: a unit of work\n    - measurements:\n        - Response time: `#seconds per task`\n        - Throughput: `#tasks per second`\n        - Response and throughput must be measured separately\n            - they are not necessarily reciprocals\n            - one cannot derive response time only from throughput, vice versa.\n\t- Percentile specification:\n\t\t- e.g. \"95% of responses ended within 1s\"\n\t\t- maps better to the human experience than *mean* alone\n\t\t- captures both mean and variance\n\t- \"Our customers fell the variance, not the mean.\" --- GE, six sigma\n\n- Diagnosis of performance\n\t- The users' claim is often about the response time\n\t\t- simple form: \"It used to take only 1s\"\n\t\t- complex form: \"It's so [...] slow\"\n\t- First steps\n\t\t- State the problem clearly\n\t\t- Define the goal state\n\t\t\t- worse: when user does not understand a quantative goal\n\t\t\t- worse: when user's expectation is impossible to meet\n\t- Tool: sequence diagram\n\t- Tool: profile\n\t\t- pitfall: skew\n\t\t\t- non-uniformity in a list of values\n\t\t\t- eliminate 1/2 calls may not eliminate 1/2 execution time\n\t\t\t- skew histogram: group calls with (range of time / counts / total time)\n\t- Estimations:\n\t\t- cost\n\t\t- return\n\t\t\t- Amdahl's law: performance improvement is proportional to how much a program uses the improved thing\n\t\t- political capital: credibility in group\n\t\t- reliability of estimations\n\n\n- Efficiency\n\t- inverse measure of waste\n\t\t- waste: how much of service time can be eliminated\n\t\t\t- without adding capacity\n\t\t\t- without sacrificing function\n\t- do not adjust the program to accommodate inefficient programs\n\n- Load\n\t- Competition for resource induced by tasks\n\t- The reason that performance testing does not catch all problems in production\n\t- measurement: utilization (usage / capacity)\n\t- High load increases response time\n\n- Impacts of Load\n    - Queueing delay\n        - delay due to waiting\n        - can be modelled by \"M/M/m\" model\n            - ideal scalable queue\n        - total = service time + queueing delay\n        - high throughput and fast response are conflicting\n            - knee: optimal load\n            - min ( response time / utilization )\n            - the actual knee of an M/M/m system is listed in table (page 10 of the paper)\n            - when load is below knee: (marginal response time) is low.\n            - when load is beyond the knee: high (marginal response time), system become unusable quickly.\n    - Coherency delay\n        - delay due to shared resource\n        - cannot be modelled with \"M/M/m\" model\n\n- Testing\n\t- may not catch all problems, still necessary\n\t- keep balance between \"no test\" and \"complete emulation of production\"\n\n- Measuring for optimization\n\t - Throughtput: easier to measure\n\t - Response time: happens at client side, and is harder to measure\n\t - People tend to measure what's easy to measure\n\t - Surrogate measures:\n        - are easy to measure\n\t\t- may work **sometimes**\n        - know their limitation and use them wisely\n\t\t- e.g. subroutine call counts, samples (i.e. not all) of subroutine execution durations\n\n- Other principles\n    - Risk less in optimizing: when everybody is fine, do not adjust the world for one program\n    - Performance is a feature\n\t- Real performance is unrevealed until the production phase\n\t- Write the program so that it's easy to fix in production\n"},"__N_SSG":true},"page":"/posts/[...slug]","query":{"slug":["2014-05-11","memo-thinking-clearly-about-performance"]},"buildId":"tlxtjnvNyuDsinQss6fzz","nextExport":false,"isFallback":false,"gsp":true,"head":[["meta",{"charSet":"utf-8"}],["script",{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=UA-39627402-1"}],["script",{"dangerouslySetInnerHTML":{"__html":"\n            window.dataLayer = window.dataLayer || [];\n            function gtag(){dataLayer.push(arguments);}\n            gtag('js', new Date());\n            gtag('config', 'UA-39627402-1', {\n              page_path: window.location.pathname,\n            });\n          "}}],["title",{"children":"memo: Thinking Clearly About Performance"}],["meta",{"httpEquiv":"X-UA-Compatible","content":"IE=edge"}],["meta",{"name":"viewport","content":"width=device-width, initial-scale=1,maximum-scale=1.5,minimum-scale=1"}],["link",{"rel":"canonical","href":"https://jokester.github.io/posts/2014-05-11/memo-thinking-clearly-about-performance"}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-555defa4e62ba07d4446.js"></script><script src="/_next/static/chunks/main-d42d109db6976c01a5e9.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/commons.2a955b2cc4cd676398e3.js" async=""></script><script src="/_next/static/chunks/pages/_app-7c12fd0ca2279e9deba3.js" async=""></script><script src="/_next/static/chunks/framework.e6a38dee2f8f3a7cf1e7.js" async=""></script><script src="/_next/static/chunks/b7536e739236ba09df46895b208080d021a349b5.79dc8a8b4f0d930fbecb.js" async=""></script><script src="/_next/static/chunks/b52a6c8fe9dfc388856b15614b0f9ba4172af7a6.1c0a2366dab843a4556e.js" async=""></script><script src="/_next/static/chunks/pages/posts/%5B...slug%5D-1862802d0a4a1972e3d1.js" async=""></script><script src="/_next/static/tlxtjnvNyuDsinQss6fzz/_buildManifest.js" async=""></script><script src="/_next/static/tlxtjnvNyuDsinQss6fzz/_ssgManifest.js" async=""></script></body></html>